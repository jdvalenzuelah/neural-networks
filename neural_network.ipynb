{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCAQVEnk-s5L"
   },
   "source": [
    "# Redes Neuronales\n",
    "Josue Valenzuela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54plteJq_QsK"
   },
   "source": [
    "### Vamos a importar la data con la utilidad prporcionada por [ zalandoresearch ](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ4fDZIX-9BC"
   },
   "outputs": [],
   "source": [
    "from utils import mnist_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn9Pj5AxAOXB"
   },
   "source": [
    "Vamos a comenzar por el set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1QmPLVJANnu"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('data', kind='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTU1gTRfBG_0"
   },
   "source": [
    "Continuamos con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWEkxsmqBNKG"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = mnist_reader.load_mnist('data', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIb1Ixw4HVAB"
   },
   "source": [
    "### Vamos a transformar los datos para poder trabajar con ellos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cex4MLIMH6ce"
   },
   "source": [
    "Vamos a comenzar convirtiendo a int64 los datos para facilitar el manejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ku5Xe5yxHzRa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.array(X_train, dtype=np.int64)\n",
    "X_test = np.array(X_test, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSfdmeW4Ij2M"
   },
   "source": [
    "Vamos a normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7hKjQRYIoyH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = (X_train / 1000.0, X_test / 1000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0X1PpRqrJl9H"
   },
   "source": [
    "Vamos a transformar los datos de label, a una forma mas apropiada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymjPy9s5KyiQ"
   },
   "outputs": [],
   "source": [
    "m_train, n_train = X_train.shape\n",
    "m_test, n_test = X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MahrmICK_OH"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(m_train, 1)\n",
    "y_test = y_test.reshape(m_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3wXDNpQD7-n"
   },
   "source": [
    "### Arquitectura de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDIzGgqVEB99"
   },
   "source": [
    "Vamos a comenzar con:\n",
    "- **Capa de entrada:** 784 neuronas, ya que es el numero de pixeles de la imagen\n",
    "- ** Capa escondida:** 125 neuronas\n",
    "- **Capa de salida:** 10 neuronas ya que es el total de prendas posibles, se detallan a continuacion:\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hkqj-_DCEzTc"
   },
   "outputs": [],
   "source": [
    "NN_ARCH = np.array( [ n_train, 125, 10 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xzxrlqe8M4Ze"
   },
   "source": [
    "## Optimizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BQhFJ5uOUk3"
   },
   "outputs": [],
   "source": [
    "from utils.neural_network import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mffE90bUOfU6"
   },
   "source": [
    "Creamos la matriz de theta en base a la arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YE7m8T-OflB"
   },
   "outputs": [],
   "source": [
    "theta_shapes  = np.hstack((\n",
    "    NN_ARCH[1:].reshape(len(NN_ARCH) - 1, 1),\n",
    "    (NN_ARCH[:-1] + 1).reshape(len(NN_ARCH) - 1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbOZlBtWM7NP"
   },
   "source": [
    "Vamos a comenzar con valores de theta aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDflJV2rOPey"
   },
   "outputs": [],
   "source": [
    "flat_thetas = flatten_list_of_arrays([\n",
    "    np.random.rand(*theta_shape)\n",
    "    for theta_shape in theta_shapes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CW8n9t9NO3_A"
   },
   "source": [
    "Comenzamos con la optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na3Bu_I_O7IM"
   },
   "outputs": [],
   "source": [
    "from scipy import optimize as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHvAMefsQoQI"
   },
   "outputs": [],
   "source": [
    "Y = (y_train == np.array(range(10))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "qHv0yiwrO7-D",
    "outputId": "10393736-7576-49b8-d427-5e79b786c94c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davalenzuela/Documents/uvg/ai/neural-network/fashion_neural_network/utils/neural_network.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(Y * np.log(a[-1]) + (1 - Y) * np.log(1 - a[-1])).sum() / len(X)\n",
      "/home/davalenzuela/Documents/uvg/ai/neural-network/fashion_neural_network/utils/neural_network.py:60: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -(Y * np.log(a[-1]) + (1 - Y) * np.log(1 - a[-1])).sum() / len(X)\n"
     ]
    }
   ],
   "source": [
    "opt_res = op.minimize(\n",
    "    fun=cost_function,\n",
    "    x0=flat_thetas,\n",
    "    args=(theta_shapes, X_train, Y),\n",
    "    method='L-BFGS-B',\n",
    "    jac=back_propagation,\n",
    "    options={'disp': True, 'maxiter': 3000}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59sDG4WiPDw2"
   },
   "source": [
    "Vamos a guardar el modelo entrenado para evitar correrlo de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlu8ZpzuM6ba"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pre-trained/pre-trained-model-v1', 'wb') as o_file:\n",
    "  pickle.dump(opt_res.x, o_file)\n",
    "  o_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos la efectividad del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a leer los datos del modelo pre entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pre-trained-model-v1', 'rb') as o_file:\n",
    "    opt_thetas = pickle.load(o_file)\n",
    "    o_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a predecir los valores en base al modelo encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = inflate_matrixes(\n",
    "    opt_thetas,\n",
    "    theta_shapes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_res = feed_forward(\n",
    "    thetas,\n",
    "    X_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a medir la precision del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lbl = np.argmax(ff_res[-1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_res = {'correct': 0, 'incorrect': 0}\n",
    "for i in range( len( ff_res[-1] ) ):\n",
    "    if(predict_lbl[i] == y_test[i][0]):\n",
    "        prediction_res['correct'] += 1\n",
    "    else:\n",
    "        prediction_res['incorrect'] +=1\n",
    "\n",
    "print(prediction_res)\n",
    "print(f\"Precisión: { round( ( prediction_res['correct'] / len( ff_res[-1] ) ) * 100 ) }%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "neural-network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
